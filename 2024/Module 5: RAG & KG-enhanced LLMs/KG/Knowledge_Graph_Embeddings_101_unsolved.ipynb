{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty4z1hvs92pD"
      },
      "source": [
        "# Introduction to Knowledge Graph Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the provided `get_data_and_setup.sh` script to download the data and set up the environment. This script will download the data and install the required libraries.\n",
        "\n",
        "```bash\n",
        "./get_data_and_setup.sh\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovC9LY87-udz"
      },
      "source": [
        "Now let's read the triples (splitted in training, validation, and test set) from the UMLS dataset, and visualise part of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "65rQCk2zGjUy",
        "outputId": "47771c8b-e9b8-47a2-b52d-0ea14cd9eb7d"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from os.path import splitext\n",
        "from typing import List, Tuple, Set, Dict, Optional, Iterable, Pattern\n",
        "\n",
        "def read_triples(path: str) -> List[Tuple[str, str, str]]:\n",
        "    triples = []\n",
        "    with open(path, 'rt') as f:\n",
        "      for line in f:\n",
        "        s, p, o = line.split('\\t')\n",
        "        triples += [(s.strip(), p.strip(), o.strip())]\n",
        "    return triples\n",
        "\n",
        "\n",
        "#Pay attention that we can change umls to wordnet or freebase\n",
        "train_triples_lst = read_triples('data/umls/train.txt')\n",
        "valid_triples_lst = read_triples('data/umls/valid.txt')\n",
        "test_triples_lst = read_triples('data/umls/test.txt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_triples_lst, columns =['Subject', 'Predicate', 'Object'])\n",
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziQ74aCnA-kK"
      },
      "source": [
        "Let's create the set $E$ entities and the set $R$ of relation types, respectively denoted as `entity_set` and `predicate_set` in the following code.\n",
        "\n",
        "Then, we associate an unique integer between $0$ and $|E| - 1$ to each entity $e \\in E$, and an unique integer between $0$ and $|R| - 1$ to each relation type $p \\in R$ -- these are saved in the `entity_to_idx` and `predicate_to_idx` dictionaries in the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eshDB9ZYgZ8I",
        "outputId": "b17baa72-bb55-4baa-cea1-1a954defd60f"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "all_triples_lst: List[Tuple[str, str, str]] = train_triples_lst + valid_triples_lst + test_triples_lst\n",
        "\n",
        "# Set E of all entities\n",
        "entity_set: Set[str] = {s for s, _, _ in all_triples_lst} | {o for _, _, o in all_triples_lst}\n",
        "# Set R of all relation types\n",
        "predicate_set: Set[str] = {p for _, p, _ in all_triples_lst}\n",
        "\n",
        "# Map every entity and predicate with an unique index from 0 to |E|\n",
        "entity_lst: List[str] = sorted(entity_set)\n",
        "predicate_lst: List[str] = sorted(predicate_set)\n",
        "\n",
        "# Entity/predicate -> index maps\n",
        "entity_to_idx: Dict[str, int] = {entity: idx for idx, entity in enumerate(entity_lst)}\n",
        "predicate_to_idx: Dict[str, int] = {predicate: idx for idx, predicate in enumerate(predicate_lst)}\n",
        "\n",
        "# Index -> entity/predicate maps\n",
        "idx_to_entity: Dict[int, str] = {idx: entity for entity, idx in entity_to_idx.items()}\n",
        "idx_to_predicate: Dict[int, str] = {idx: predicate for predicate, idx in predicate_to_idx.items()}\n",
        "\n",
        "print(\"|E| is\", len(entity_set), \"while |R| is\", len(predicate_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDZO9nnhC0rO"
      },
      "source": [
        "We now transform the training, validation, and test set in PyTorch matrices with shape $|T| \\times 3$, where $T \\subseteq E \\times R \\times E$ denotes the set of triples and the first, second, and third column contain the indices of the subjects, predicates, and objects of the triples, respectively. Given a set of triples $T$, this code produces a matrix $\\mathbf{T} \\in \\mathbb{N}_{+}^{|T| \\times 3}$ containing the indices of the entities and relation types in $T$.\n",
        "\n",
        "Below displays the first rows of the matrix generated from the UMLS training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "b3S48kXxhq8H",
        "outputId": "d419e570-b371-4dd3-e385-e8d56e09d8b3"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "\n",
        "# Convert the training, validation, and test sets to numpy matrices with shape |S| x 3\n",
        "def triples_to_matrix(triple_lst: List[Tuple[str, str, str]]) -> np.array:\n",
        "  index_lst = [(entity_to_idx[s], predicate_to_idx[p], entity_to_idx[o]) for s, p, o in triple_lst]\n",
        "  return np.array(index_lst, dtype=np.int32)\n",
        "\n",
        "train_np = triples_to_matrix(train_triples_lst)\n",
        "valid_np = triples_to_matrix(valid_triples_lst)\n",
        "test_np = triples_to_matrix(test_triples_lst)\n",
        "all_np = triples_to_matrix(all_triples_lst)\n",
        "\n",
        "# Now we need to start using PyTorch tensors -- let's first check if we have GPU support\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Let's convert the training, validation, and test sets to (PyTorch) tensors\n",
        "train_t = torch.tensor(train_np, dtype=torch.long, device=device)\n",
        "valid_t = torch.tensor(valid_np, dtype=torch.long, device=device)\n",
        "test_t = torch.tensor(test_np, dtype=torch.long, device=device)\n",
        "all_t = torch.tensor(all_np, dtype=torch.long, device=device)\n",
        "\n",
        "train_df = pd.DataFrame(train_t.cpu().numpy(), columns =['Subject Indices', 'Predicate Indices', 'Object Indices'])\n",
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9NV8HKQLHmf"
      },
      "source": [
        "Let's now define the model we will be using. Here it shows DistMult's code, where the scoring function is simply defined as $f(\\mathbf{s}, \\mathbf{p}, \\mathbf{o}) = \\langle \\mathbf{s}, \\mathbf{p}, \\mathbf{o} \\rangle = \\sum_{i} \\mathbf{s}_{i} \\mathbf{p}_{i} \\mathbf{o}_{i}$.\n",
        "\n",
        "Note that the model has two methods:\n",
        "- The `score` method receives a batch of triples, and produces a score for each of the triples.\n",
        "- The `forward` method has three arguments, `s` for subjects, `p` for predicates, and `o` for objects: if one of them is set to `None`, this method efficiently produces a score for all candidate entities or relation types for replacing the missing argument. This will be extremely useful to compute some training objective efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOTBelFK4PAA"
      },
      "outputs": [],
      "source": [
        "# Let's create a PyTorch link prediction model -- we will use the DistMult scoring function\n",
        "\n",
        "class DistMult(nn.Module):\n",
        "    def __init__(self, nb_entities: int, nb_predicates: int, embedding_size: int):\n",
        "        super().__init__()\n",
        "        self.nb_entities = nb_entities\n",
        "        self.nb_predicates = nb_predicates\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # This is the encoder part of the model, and the emeddings for the entities and relation types\n",
        "        # represent the parameters θ of the encoder.\n",
        "        self.entity_embeddings = nn.Embedding(nb_entities, self.embedding_size, sparse=True)\n",
        "        self.predicate_embeddings = nn.Embedding(nb_predicates, self.embedding_size, sparse=True)\n",
        "\n",
        "        # Small trick from https://github.com/facebookresearch/kbc/\n",
        "        self.entity_embeddings.weight.data *= 1e-3\n",
        "        self.predicate_embeddings.weight.data *= 1e-3\n",
        "\n",
        "    def score(self, triple: Tensor) -> Tensor:\n",
        "        # triple is a batch_size x 3 tensor containing a batch of triples, where triple[0], triple[1], and triple[2]\n",
        "        # correspond to the indices of the subjects, predicates, and objects, respectively.\n",
        "\n",
        "        # We first look up the embedding of the subjects, predicates, and objects of the input triples ..\n",
        "        # TODO: Implement the scoring function of DistMult\n",
        "\n",
        "        # [B] Tensor\n",
        "        return res\n",
        "\n",
        "    def forward(self, s: Optional[Tensor], p: Optional[Tensor], o: Optional[Tensor]) -> Tensor:\n",
        "        # s, p, and o are the indices of subjects, predicates, and objects, respecitvely.\n",
        "        # This function is similar to the previous score() but it requires you not to specify one among the\n",
        "        # subject, predicate, and object of a batch of triples, and gives you a score for all possible candidates\n",
        "        assert [s, p, o].count(None) <= 1, \"s, p, or o should be None\"\n",
        "\n",
        "        s_emb = self.entity_embeddings(s) if s is not None else self.entity_embeddings.weight\n",
        "        p_emb = self.predicate_embeddings(p) if p is not None else self.predicate_embeddings.weight\n",
        "        o_emb = self.entity_embeddings(o) if o is not None else self.entity_embeddings.weight\n",
        "\n",
        "        # [B] Tensor\n",
        "        scores = None\n",
        "\n",
        "        if p is None:\n",
        "          # If the predicate is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # predicates in R as predicate values.\n",
        "          #TODO: Implement the scoring function given the predicate is None\n",
        "          ...\n",
        "\n",
        "        elif s is None:\n",
        "          # If the subject is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # entities in E as subject values.\n",
        "          scores = (p_emb * o_emb) @ s_emb.t()\n",
        "        elif o is None:\n",
        "          # If the object is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # entities in E as object values.\n",
        "          scores = (s_emb * p_emb) @ o_emb.t()\n",
        "        else:\n",
        "          # Subject, predicare, and object values were specified -- we compute the score of the triple.\n",
        "          scores = self.score(torch.cat([s.view(-1, 1), p.view(-1, 1), o.view(-1, 1)], dim=1))\n",
        "\n",
        "        assert scores is not None\n",
        "        return scores\n",
        "\n",
        "    def factor(self, idx: Tensor, is_entity: bool = True) -> Tensor:\n",
        "      # This method is used for regularisation -- more on this later.\n",
        "      embedding_layer = self.entity_embeddings if is_entity is True else self.predicate_embeddings\n",
        "      emb = embedding_layer(idx)\n",
        "      return emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will show TransE's code, where the scoring function is defined as $f(\\mathbf{s}, \\mathbf{p}, \\mathbf{o}) = -\\|\\mathbf{s} + \\mathbf{p} - \\mathbf{o}\\|_{2}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RESCAL(nn.Module):\n",
        "    def __init__(self, nb_entities: int, nb_predicates: int, embedding_size: int):\n",
        "        super().__init__()\n",
        "        self.nb_entities = nb_entities\n",
        "        self.nb_predicates = nb_predicates\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # This is the encoder part of the model, and the emeddings for the entities and relation types\n",
        "        # represent the parameters θ of the encoder.\n",
        "        self.entity_embeddings = nn.Embedding(nb_entities, self.embedding_size, sparse=True)\n",
        "        self.predicate_matrices = nn.Embedding(nb_predicates, self.embedding_size * self.embedding_size, sparse=True)\n",
        "\n",
        "        # Small trick from\n",
        "        \n",
        "        self.entity_embeddings.weight.data *= 1e-3\n",
        "        self.predicate_matrices.weight.data *= 1e-3\n",
        "\n",
        "    def score(self, triple: Tensor) -> Tensor:\n",
        "        \n",
        "      ...\n",
        "    \n",
        "    def forward(self, s: Optional[Tensor], p: Optional[Tensor], o: Optional[Tensor]) -> Tensor:\n",
        "\n",
        "        assert [s, p, o].count(None) <= 1, \"s, p, or o should be None\"\n",
        "\n",
        "        s_emb = self.entity_embeddings(s) if s is not None else self.entity_embeddings.weight\n",
        "        p_emb = self.predicate_matrices(p).view(-1, self.embedding_size, self.embedding_size) if p is not None else self.predicate_matrices.weight.view(-1, self.embedding_size, self.embedding_size)\n",
        "        o_emb = self.entity_embeddings(o) if o is not None else self.entity_embeddings.weight\n",
        "\n",
        "        scores = None\n",
        "\n",
        "        if p is None:\n",
        "          scores = (s_emb.unsqueeze(1) @ o_emb.unsqueeze(2) @ p_emb.view(-1, self.embedding_size, self.embedding_size).transpose(1, 2)).view(-1, self.nb_predicates)\n",
        "        elif s is None:\n",
        "          scores = (p_emb @ o_emb.unsqueeze(2)).view(-1, self.nb_entities)\n",
        "        elif o is None:\n",
        "          scores = (s_emb.unsqueeze(1) @ p_emb).view(-1, self.nb_entities)\n",
        "        else:\n",
        "          scores = self.score(torch.cat([s.view(-1, 1), p.view(-1, 1), o.view(-1, 1)], dim=1))\n",
        "\n",
        "        assert scores is not None\n",
        "        return scores\n",
        "    \n",
        "    def factor(self, idx: Tensor, is_entity: bool = True) -> Tensor:\n",
        "        embedding_layer = self.entity_embeddings if is_entity is True else self.predicate_matrices\n",
        "        emb = embedding_layer(idx)\n",
        "        return emb\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igRkRTnvimr8"
      },
      "source": [
        "Here it shows ComplEx's code, where the scoring function is defined as $f(\\mathbf{s}, \\mathbf{p}, \\mathbf{o}) = \\text{Re}(\\langle \\mathbf{s}, \\mathbf{p}, \\overline{\\mathbf{o}} \\rangle)$.\n",
        "\n",
        "Note that the model has two methods:\n",
        "- The `score` method receives a batch of triples, and produces a score for each of the triples.\n",
        "- The `forward` method has three arguments, `s` for subjects, `p` for predicates, and `o` for objects: if one of them is set to `None`, this method efficiently produces a score for all candidate entities or relation types for replacing the missing argument. This will be extremely useful to compute some training objective efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNe8_i6WyK24"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Let's create a PyTorch link prediction model -- we will use the ComplEx scoring function\n",
        "\n",
        "class ComplEx(nn.Module):\n",
        "    def __init__(self, nb_entities: int, nb_predicates: int, embedding_size: int):\n",
        "        super().__init__()\n",
        "        self.nb_entities = nb_entities\n",
        "        self.nb_predicates = nb_predicates\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # Remeber that ComplEx has complex embeddings -- here we will use\n",
        "        # x[:embedding_size] as the real part, and x[embedding_size:] as the\n",
        "        # imaginary part of the representations\n",
        "        self.entity_embeddings = nn.Embedding(nb_entities, self.embedding_size * 2, sparse=True)\n",
        "        self.predicate_embeddings = nn.Embedding(nb_predicates, self.embedding_size * 2, sparse=True)\n",
        "\n",
        "        # Small trick from https://github.com/facebookresearch/kbc/\n",
        "        self.entity_embeddings.weight.data *= 1e-3\n",
        "        self.predicate_embeddings.weight.data *= 1e-3\n",
        "\n",
        "    def score(self, triple: Tensor) -> Tensor:\n",
        "        # triple is a batch_size x 3 tensor containing a batch of triples, where triple[0], triple[1], and triple[2]\n",
        "        # correspond to the indices of the subjects, predicates, and objects, respectively.\n",
        "\n",
        "        ...\n",
        "\n",
        "\n",
        "    def forward(self, s: Optional[Tensor], p: Optional[Tensor], o: Optional[Tensor]) -> Tensor:\n",
        "        # s, p, and o are the indices of subjects, predicates, and objects, respecitvely.\n",
        "        # This function is similar to the previous score() but it requires you not to specify one among the\n",
        "        # subject, predicate, and object of a batch of triples, and gives you a score for all possible candidates\n",
        "        assert [s, p, o].count(None) <= 1, \"s, p, or o should be None\"\n",
        "\n",
        "        s_emb = self.entity_embeddings(s) if s is not None else self.entity_embeddings.weight\n",
        "        p_emb = self.predicate_embeddings(p) if p is not None else self.predicate_embeddings.weight\n",
        "        o_emb = self.entity_embeddings(o) if o is not None else self.entity_embeddings.weight\n",
        "\n",
        "        # Let's extract the real and imaginary part from the subject, predicate, and object embeddings\n",
        "        s_real, s_img = s_emb[:, :self.embedding_size], s_emb[:, self.embedding_size:]\n",
        "        p_real, p_img = p_emb[:, :self.embedding_size], p_emb[:, self.embedding_size:]\n",
        "        o_real, o_img = o_emb[:, :self.embedding_size], o_emb[:, self.embedding_size:]\n",
        "\n",
        "        # [B] Tensor\n",
        "        scores = None\n",
        "\n",
        "        if p is None:\n",
        "          # If the predicate is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # predicates in R as predicate values.\n",
        "          scores1_p = (s_real * o_real + s_img * o_img) @ p_real.t()\n",
        "          scores2_p = (s_real * o_img - s_img * o_real) @ p_img.t()\n",
        "          scores = scores1_p + scores2_p\n",
        "        elif s is None:\n",
        "          # If the subject is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # entities in E as subject values.\n",
        "          scores1_s = (p_real * o_real + p_img * o_img) @ s_real.t()\n",
        "          scores2_s = (p_real * o_img - p_img * o_real) @ s_img.t()\n",
        "          scores = scores1_s + scores2_s\n",
        "        elif o is None:\n",
        "          # If the object is not specified, we compute the scores of all the triples obtained by using the\n",
        "          # entities in E as object values.\n",
        "          scores1_o = (p_real * s_real - p_img * s_img) @ o_real.t()\n",
        "          scores2_o = (p_real * s_img + p_img * s_real) @ o_img.t()\n",
        "          scores = scores1_o + scores2_o\n",
        "        else:\n",
        "          # Subject, predicare, and object values were specified -- we compute the score of the triple.\n",
        "          scores = self.score(torch.cat([s.view(-1, 1), p.view(-1, 1), o.view(-1, 1)], dim=1))\n",
        "\n",
        "        assert scores is not None\n",
        "        return scores\n",
        "\n",
        "    def factor(self, idx: Tensor, is_entity: bool = True) -> Tensor:\n",
        "      embedding_layer = self.entity_embeddings if is_entity is True else self.predicate_embeddings\n",
        "      emb = embedding_layer(idx)\n",
        "      emb_real, emb_img = emb[:, :self.embedding_size], emb[:, self.embedding_size:]\n",
        "      return torch.sqrt(emb_real ** 2 + emb_img ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F09Z4vxPvab"
      },
      "source": [
        "After creating the model, we know create the regularisers, implemented by the classes `F2` and `N3`. Here, `F2` implements the squared Frobenius norm $\\Omega(\\mathbf{e}) = \\lVert \\mathbf{e} \\rVert_{2}^{2}$, while `N3` implements the nuclear 3-norm proposed by [1].\n",
        "\n",
        "[1] Lacroix et al. Canonical Tensor Decomposition for Knowledge Base Completion, ICML 2018 https://arxiv.org/abs/1806.07297"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikh_cUOa2I82"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Let's create two regularisers\n",
        "\n",
        "class F2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, factors: List[Tensor]):\n",
        "        norm = sum(torch.sum(f ** 2) for f in factors)\n",
        "        return norm / factors[0].shape[0]\n",
        "\n",
        "\n",
        "class N3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, factors: List[Tensor]):\n",
        "        norm = sum(torch.sum(torch.abs(f) ** 3) for f in factors)\n",
        "        return norm / factors[0].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG9kmG2PSNSs"
      },
      "source": [
        "We now instantiate the model -- we set the embedding size (`embedding_size` in the code, $d$ in the slides) to 100, and try to calculate the score of the first 100 triples in the training set (remember that the embeddings are initialised at random).\n",
        "\n",
        "The output cell shows the computation graph used by PyTorch to compute the scores of these triples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1cMXtIoLrJV",
        "outputId": "c548577b-94b3-4b77-b1b1-4fee01b01da9"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Let's create the model (with random initial embeddings), move it on CPU/GPU, and see what scores the model gives us before training\n",
        "nb_entities = len(entity_set)\n",
        "nb_predicates = len(predicate_set)\n",
        "\n",
        "embedding_size = 500\n",
        "# model = RESCAL(nb_entities=nb_entities, nb_predicates=nb_predicates, embedding_size=embedding_size).to(device)\n",
        "model = DistMult(nb_entities=nb_entities, nb_predicates=nb_predicates, embedding_size=embedding_size).to(device)\n",
        "# model = ComplEx(nb_entities=nb_entities, nb_predicates=nb_predicates, embedding_size=embedding_size).to(device)\n",
        "\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Let's see what scores we get for the first 10 triples in the training set\n",
        "print(model.score(train_t[:10, :]))\n",
        "\n",
        "import torchlens as tl\n",
        "model_history = tl.log_forward_pass(model, (train_t[:10, 0], train_t[:10, 1], train_t[:10, 2]), layers_to_save='all', vis_opt='rolled')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4BflEljTfGz"
      },
      "source": [
        "We now implement the evaluation metric -- we implement both MRR and Hits@$k$.\n",
        "\n",
        "We are given a test set of triples $T = \\{ t_{1}, t_{2}, \\ldots, t_{|T|} \\}$. For each test triple $t_{i} = \\langle s, p, o \\rangle \\in E \\times R \\times E$, we check how accurately we can predict $o$ from $\\langle s, p, \\cdot \\rangle$ and $s$ from $\\langle \\cdot, p, o \\rangle$.\n",
        "\n",
        "More formally, given a triple $t_{i} = \\langle s, p, o \\rangle$, we calculate a score for all entities $e \\in E$ based on the score associated by the model to $\\langle s, p, e \\rangle$, and sort them in descending order: the position of the true object $o$ in this ranking will be the *object rank* of $t_{i}$. We then repeat the same operation for the subject $s$.\n",
        "\n",
        "Note that, when sorting the entities by their scores in descending order, we may rank the correct object $o$ or subject $s$ below some other triple that also appears in the training, validation, or test set -- this is not strictly an error, so we do not consider these cases when computing the subject and object ranks of a test triple. In the literature, this is referred to as the *filtered setting* -- see [1] for more information about this.\n",
        "\n",
        "Then, based on the (subject and object) ranks of all of the test triples in $T$, we compute the following metrics:\n",
        "\n",
        "$\\text{MRR} = \\frac{1}{2|T|} \\sum_{i} \\frac{1}{\\text{Rank}^{s}_{t} + \\text{Rank}^{o}_{t}} \\qquad \\text{and} \\qquad \\text{Hits@}k = \\frac{|\\{ t \\in T : \\text{Rank}^{s}_{t} \\leq k \\}| + |\\{ t \\in T : \\text{Rank}^{o}_{t} \\leq k \\}|}{2|T|}$\n",
        "\n",
        "[1] Bordes et al. Translating Embeddings for Modeling\n",
        "Multi-relational Data. NIPS 2013 https://papers.nips.cc/paper_files/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y9RsJ9E_ErF"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Evaluation function!\n",
        "def evaluate(test_triples: Tensor, all_triples: Tensor, model: nn.Module, batch_size: int = 8192):\n",
        "    sp_to_o, po_to_s = {}, {}\n",
        "\n",
        "    # We need these to compute the filtered ranks\n",
        "    for s, p, o in all_triples:\n",
        "        s_idx, p_idx, o_idx = s.item(), p.item(), o.item()\n",
        "\n",
        "        sp_key = (s_idx, p_idx)\n",
        "        po_key = (p_idx, o_idx)\n",
        "\n",
        "        if sp_key not in sp_to_o:\n",
        "            sp_to_o[sp_key] = []\n",
        "\n",
        "        if po_key not in po_to_s:\n",
        "            po_to_s[po_key] = []\n",
        "\n",
        "        sp_to_o[sp_key] += [o_idx]\n",
        "        po_to_s[po_key] += [s_idx]\n",
        "\n",
        "    hits = dict()\n",
        "    hits_l = dict()\n",
        "    hits_r = dict()\n",
        "\n",
        "    hits_at = [1, 3, 5, 10, 20, 50, 100]\n",
        "\n",
        "    for hits_at_value in hits_at:\n",
        "        hits[hits_at_value] = 0.0\n",
        "        hits_l[hits_at_value] = 0.0\n",
        "        hits_r[hits_at_value] = 0.0\n",
        "\n",
        "    def hits_at_n(n_, rank, is_left=True):\n",
        "        if rank <= n_:\n",
        "            hits[n_] = hits.get(n_, 0) + 1\n",
        "\n",
        "            hits_x = hits_l if is_left else hits_r\n",
        "            hits_x[n_] = hits_x.get(n_, 0) + 1\n",
        "\n",
        "    counter = 0\n",
        "    mrr = 0.0\n",
        "\n",
        "    dataset = TensorDataset(test_triples)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    ranks_l, ranks_r = [], []\n",
        "\n",
        "    for batch_ in data_loader:\n",
        "        batch_triples = batch_[0]\n",
        "        batch_size = batch_triples.shape[0]\n",
        "        counter += batch_size * 2\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            scores_o = model.forward(s=batch_triples[:, 0], p=batch_triples[:, 1], o=None).cpu().numpy()\n",
        "            scores_s = model.forward(s=None, p=batch_triples[:, 1], o=batch_triples[:, 2]).cpu().numpy()\n",
        "\n",
        "        for elem_idx in range(batch_size):\n",
        "            s_idx, p_idx, o_idx = batch_triples[elem_idx, 0], batch_triples[elem_idx, 1], batch_triples[elem_idx, 2]\n",
        "\n",
        "            # Code for the filtered setting\n",
        "            sp_key = (s_idx.item(), p_idx.item())\n",
        "            po_key = (p_idx.item(), o_idx.item())\n",
        "\n",
        "            o_to_remove = sp_to_o[sp_key]\n",
        "            s_to_remove = po_to_s[po_key]\n",
        "\n",
        "            for tmp_o_idx in o_to_remove:\n",
        "                if tmp_o_idx != o_idx:\n",
        "                    scores_o[elem_idx, tmp_o_idx] = - np.infty\n",
        "\n",
        "            for tmp_s_idx in s_to_remove:\n",
        "                if tmp_s_idx != s_idx:\n",
        "                    scores_s[elem_idx, tmp_s_idx] = - np.infty\n",
        "            # End of code for the filtered setting\n",
        "\n",
        "            rank_l = 1 + np.argsort(np.argsort(- scores_s[elem_idx, :]))[s_idx]\n",
        "            rank_r = 1 + np.argsort(np.argsort(- scores_o[elem_idx, :]))[o_idx]\n",
        "\n",
        "            ranks_l += [rank_l]\n",
        "            ranks_r += [rank_r]\n",
        "\n",
        "            mrr += 1.0 / rank_l\n",
        "            mrr += 1.0 / rank_r\n",
        "\n",
        "            for n in hits_at:\n",
        "                hits_at_n(n, rank_l, is_left=True)\n",
        "\n",
        "            for n in hits_at:\n",
        "                hits_at_n(n, rank_r, is_left=False)\n",
        "\n",
        "    counter = float(counter)\n",
        "\n",
        "    mrr /= counter\n",
        "\n",
        "    for n in hits_at:\n",
        "        hits[n] /= counter\n",
        "        hits_l[n] /= (counter // 2)\n",
        "        hits_r[n] /= (counter // 2)\n",
        "\n",
        "    metrics = dict()\n",
        "    metrics['mrr'] = mrr\n",
        "    for n in hits_at:\n",
        "        metrics['hits@{}'.format(n)] = hits[n]\n",
        "\n",
        "        metrics['hits_l@{}'.format(n)] = hits_l[n]\n",
        "        metrics['hits_r@{}'.format(n)] = hits_r[n]\n",
        "\n",
        "    metrics['ranks_l'] = ranks_l\n",
        "    metrics['ranks_r'] = ranks_r\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4hs_rfzJ0u24",
        "outputId": "e96552dc-79e6-40bc-c1df-caa46cfb8f17"
      },
      "outputs": [],
      "source": [
        "train_metrics = evaluate(test_triples=train_t, all_triples=all_t, model=model)\n",
        "\n",
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the histogram using seaborn\n",
        "sns.histplot(train_metrics['ranks_l'] + train_metrics['ranks_r'], bins='auto', kde=False)\n",
        "\n",
        "plt.xlabel('Rank Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Rank Frequency Histogram')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9kx34d-rskN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "0lHkKr7pNKyw",
        "outputId": "64401030-c3fb-473c-a8c3-7e3d2091c1fa"
      },
      "outputs": [],
      "source": [
        "# Let's train this model! First, let's implement a training loop\n",
        "\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "optimiser = optim.Adagrad(model.parameters(), lr=0.1)\n",
        "\n",
        "#make sure to play with the regulariser weight to see how it affects the model\n",
        "regulariser = F2()\n",
        "\n",
        "nb_epochs = 100\n",
        "batch_size = 128\n",
        "regulariser_weight = 0.001\n",
        "\n",
        "dataset = TensorDataset(train_t)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model.train()\n",
        "\n",
        "group_patterns: Iterable[Tuple[Pattern, str]] = (\n",
        "    (r'^(subject(_|-))(.*)', 'subject'),\n",
        "    (r'^(object(_|-))(.*)', 'object'),\n",
        "    (r'^(aggregate(_|-))(.*)', 'aggregate'),\n",
        "    (r'^(train(_|-))(.*)', 'training'),\n",
        "    (r'^(val(_|-))(.*)', 'validation'),\n",
        "    (r'^(test(_|-))(.*)', 'test'),\n",
        ")\n",
        "\n",
        "liveloss = PlotLosses(group_patterns=group_patterns)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for epoch_no in range(1, nb_epochs + 1):\n",
        "  for batch_no, batch in enumerate(data_loader):\n",
        "    triple_batch = batch[0]\n",
        "    # Given the predicate and the object of the triple, compute a score for all possible subjects\n",
        "    s_scores = model.forward(s=None, p=triple_batch[:, 1], o=triple_batch[:, 2])\n",
        "\n",
        "    # Given the subject and the predicate of the triple, compute a scofe for all possible objects\n",
        "    o_scores = model.forward(s=triple_batch[:, 0], p=triple_batch[:, 1], o=None)\n",
        "\n",
        "    # Calculate the mismatch between the predicted scores and the gold truth -- the true subjects and objects of the triples\n",
        "    s_loss = loss_function(s_scores, triple_batch[:, 0])\n",
        "    o_loss = loss_function(o_scores, triple_batch[:, 2])\n",
        "\n",
        "    factors = [model.factor(triple_batch[:, 0], is_entity=True),\n",
        "               model.factor(triple_batch[:, 1], is_entity=False),\n",
        "               model.factor(triple_batch[:, 2], is_entity=True)]\n",
        "\n",
        "    # The loss is given by the \"mismatch (loss) value\" mentioned earlier, and a regularisation term\n",
        "    loss = s_loss + o_loss + regulariser_weight * regulariser(factors)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # Compute the gradient of the training objective (L(θ) + λΩ(θ)) with respect to θ (entity and predicate embeddings)\n",
        "    loss.backward()\n",
        "\n",
        "    # Perform one stochastic gradient descent step\n",
        "    optimiser.step()\n",
        "\n",
        "  train_metrics = evaluate(test_triples=train_t, all_triples=all_t, model=model)\n",
        "  valid_metrics = evaluate(test_triples=valid_t, all_triples=all_t, model=model)\n",
        "  test_metrics = evaluate(test_triples=test_t, all_triples=all_t, model=model)\n",
        "\n",
        "  logs = {'subject_loss': s_loss.item(), 'object_loss': o_loss.item(), 'aggregate_loss': loss.item(),\n",
        "          'train_MRR': train_metrics['mrr'], 'val_MRR': valid_metrics['mrr'], 'test_MRR': test_metrics['mrr']}\n",
        "\n",
        "  liveloss.update(logs)\n",
        "  liveloss.send()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tpJgztOgxXK3",
        "outputId": "fc683950-6ead-4f37-b8ce-abc18fe53a54"
      },
      "outputs": [],
      "source": [
        "train_metrics = evaluate(test_triples=train_t, all_triples=all_t, model=model)\n",
        "valid_metrics = evaluate(test_triples=valid_t, all_triples=all_t, model=model)\n",
        "# test_metrics = evaluate(test_triples=test_t, all_triples=all_t, model=model)\n",
        "\n",
        "sns.histplot(train_metrics['ranks_l'] + train_metrics['ranks_r'], bins='auto', kde=False)\n",
        "\n",
        "plt.xlabel('Rank Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Rank Frequency Histogram')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "asJUUMFj0fNN",
        "outputId": "b0f326c1-5e28-4c53-eb0b-90997acb67cb"
      },
      "outputs": [],
      "source": [
        "sns.histplot(valid_metrics['ranks_l'] + valid_metrics['ranks_r'], bins='auto', kde=False)\n",
        "\n",
        "plt.xlabel('Rank Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Rank Frequency Histogram')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use the implemented model to find a prediction of 2 random nodes connected by a random edge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
